{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d325bdd2-197a-406a-90a8-79862cb9074e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b6240e-d820-4844-a277-0834043d5e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uploaded to s3://smwu-cv-team-2-s3/models/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# S3 클라이언트 생성\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# S3 버킷 이름과 업로드 경로 설정\n",
    "bucket_name = 'smwu-cv-team-2-s3'  # 사용할 S3 버킷 이름\n",
    "model_path = 'models/best_model.pth'  # S3에 저장할 경로\n",
    "local_model_file = 'best_model_34.pth'  # SageMaker에서 저장한 로컬 모델 파일 경로\n",
    "\n",
    "# 로컬 파일을 S3로 업로드\n",
    "s3.upload_file(local_model_file, bucket_name, model_path)\n",
    "print(f\"Model uploaded to s3://{bucket_name}/{model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775fd4c6-b9eb-4724-88ed-3cfbf6de4b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "SageMaker Model created successfully!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# SageMaker에서 모델 생성\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=f\"s3://smwu-cv-team-2-s3/models/best_model.pth\",  # S3 모델 파일 경로\n",
    "    role='arn:aws:iam::730335373015:role/service-role/AmazonSageMaker-ExecutionRole-20240815T144726',  # SageMaker 실행 역할(Role)\n",
    "    entry_point='inference.py',  # 추론 스크립트 경로 (아래에서 작성할 예정)\n",
    "    framework_version='1.9.1',\n",
    "    py_version='py38'\n",
    ")\n",
    "\n",
    "print(\"SageMaker Model created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76191e85-0726-4dab-b1da-79af89453bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Inference Image URI: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.13.1-gpu-py39\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "# 필요한 설정\n",
    "region = \"us-east-1\"  # SageMaker 노트북이 실행 중인 지역\n",
    "framework = \"pytorch\"\n",
    "version = \"1.13.1\"  # PyTorch 버전 (학습 시 사용한 버전)\n",
    "py_version = \"py39\"  # Python 버전\n",
    "instance_type = \"ml.g4dn.2xlarge\"  # GPU 인스턴스 타입\n",
    "\n",
    "# GPU 서빙 컨테이너 이미지 URI 가져오기\n",
    "image_uri = image_uris.retrieve(\n",
    "    framework=framework,\n",
    "    region=region,\n",
    "    version=version,\n",
    "    py_version=py_version,\n",
    "    instance_type=instance_type,\n",
    "    image_scope=\"inference\"  # 서빙용 컨테이너\n",
    ")\n",
    "\n",
    "print(f\"PyTorch Inference Image URI: {image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8325243-b66d-4a45-a029-935e22f7b82b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference.py uploaded to s3://smwu-cv-team-2-s3/scripts/inference.py\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = \"smwu-cv-team-2-s3\"  # 버킷 이름\n",
    "inference_file = \"inference.py\"\n",
    "inference_path = \"scripts/inference.py\"  # S3에 저장할 경로\n",
    "\n",
    "# 파일 업로드\n",
    "s3.upload_file(inference_file, bucket_name, inference_path)\n",
    "print(f\"inference.py uploaded to s3://{bucket_name}/{inference_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e55a4a1-e9a5-459a-9816-626e98c9c0da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file compressed to best_model_34.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "# .tar.gz 파일 생성\n",
    "with tarfile.open(\"best_model_34.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"best_model_34.pth\", arcname=\"best_model_34.pth\")\n",
    "\n",
    "print(\"Model file compressed to best_model_34.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f601a-47e8-4843-ae5a-cade7915babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79c8a07-c8f3-4c03-8433-05baec00d234",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to s3://smwu-cv-team-2-s3/models/final7_model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = \"smwu-cv-team-2-s3\"\n",
    "s3_model_path = \"models/final7_model.tar.gz\"\n",
    "\n",
    "# S3로 파일 업로드\n",
    "s3.upload_file('model.tar.gz', bucket_name, s3_model_path)\n",
    "print(f\"File uploaded to s3://{bucket_name}/{s3_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e260d66-0b9c-4547-a271-f84f4ca7f373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# S3 경로 설정\n",
    "bucket_name = 'smwu-cv-team-2-s3'  # S3 버킷 이름\n",
    "s3_key = 'models/final7_model.tar.gz'  # S3에서 파일 경로\n",
    "model_data = f\"s3://{bucket_name}/{s3_key}\"\n",
    "\n",
    "# SageMaker Role 설정\n",
    "role = 'arn:aws:iam::730335373015:role/service-role/AmazonSageMaker-ExecutionRole-20240815T144726'\n",
    "\n",
    "# PyTorch 모델 생성\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    entry_point='inference.py',  \n",
    "    framework_version='1.13.1',\n",
    "    py_version='py39'\n",
    ")\n",
    "\n",
    "print(\"Model created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a439b2-c0d2-4b7f-a4da-a93dbbc01efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!Endpoint deployed: 34-endpoint\n"
     ]
    }
   ],
   "source": [
    "# 엔드포인트 배포\n",
    "predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,  # 엔드포인트 인스턴스 수\n",
    "    instance_type='ml.g4dn.2xlarge',  # 인스턴스 유형\n",
    "    endpoint_name='34-endpoint'  # 엔드포인트 이름\n",
    ")\n",
    "\n",
    "print(f\"Endpoint deployed: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd25bd-71ea-421f-86bb-c68f13162a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6fbb9-6828-486a-ab18-0ae8d49aa344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
