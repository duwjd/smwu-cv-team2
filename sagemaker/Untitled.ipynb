{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8aa1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 06:53:39.303409: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-24 06:53:40.001412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732431220.265188     902 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732431220.371484     902 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-24 06:53:40.973886: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1732431251.086716     902 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Found 607 images belonging to 2 classes.\n",
      "Found 171 images belonging to 2 classes.\n",
      "Found 298 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 17s/step - accuracy: 0.4698 - auc: 0.4672 - loss: 0.9229 - precision: 0.5305 - recall: 0.5506 - val_accuracy: 0.5497 - val_auc: 0.5386 - val_loss: 0.7042 - val_precision: 0.5497 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 19s/step - accuracy: 0.5787 - auc: 0.5821 - loss: 0.7121 - precision: 0.6279 - recall: 0.7321 - val_accuracy: 0.5497 - val_auc: 0.5410 - val_loss: 0.7176 - val_precision: 0.5497 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 18s/step - accuracy: 0.5193 - auc: 0.4485 - loss: 0.8003 - precision: 0.5985 - recall: 0.6631 - val_accuracy: 0.4678 - val_auc: 0.5256 - val_loss: 0.7004 - val_precision: 0.5652 - val_recall: 0.1383 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 17s/step - accuracy: 0.5073 - auc: 0.4471 - loss: 0.8208 - precision: 0.5675 - recall: 0.6182 - val_accuracy: 0.6023 - val_auc: 0.5287 - val_loss: 0.6880 - val_precision: 0.5833 - val_recall: 0.9681 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m703s\u001b[0m 17s/step - accuracy: 0.5169 - auc: 0.5069 - loss: 0.7518 - precision: 0.5636 - recall: 0.6962 - val_accuracy: 0.5556 - val_auc: 0.5353 - val_loss: 0.7212 - val_precision: 0.5529 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 15s/step - accuracy: 0.5242 - auc: 0.5099 - loss: 0.7410 - precision: 0.5754 - recall: 0.6989 - val_accuracy: 0.5497 - val_auc: 0.5311 - val_loss: 0.7558 - val_precision: 0.5497 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m35/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m31s\u001b[0m 10s/step - accuracy: 0.5177 - auc: 0.4791 - loss: 0.8090 - precision: 0.5508 - recall: 0.8003"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import resnet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "class DefectClassifier:\n",
    "    def __init__(self, img_size=(480, 480), batch_size=16):\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        \n",
    "    def create_model(self):\n",
    "        \"\"\"이진 분류를 위한 ResNet50 모델 생성\"\"\"\n",
    "        base_model = resnet.ResNet50(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(*self.img_size, 3),\n",
    "            pooling='avg'\n",
    "        )\n",
    "        # 전이학습을 위해 베이스 모델 동결\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(1, activation='sigmoid')  # 이진 분류를 위한 시그모이드 활성화\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',\n",
    "                    tf.keras.metrics.Precision(),\n",
    "                    tf.keras.metrics.Recall(),\n",
    "                    tf.keras.metrics.AUC()]\n",
    "        )\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def prepare_data(self, data_dir):\n",
    "        \"\"\"데이터 제너레이터 설정\"\"\"\n",
    "        train_dir = os.path.join(data_dir, 'train')\n",
    "        val_dir = os.path.join(data_dir, 'val')\n",
    "        test_dir = os.path.join(data_dir, 'test')\n",
    "        \n",
    "        # 데이터 증강 설정\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "        # 검증 및 테스트 데이터는 증강하지 않음\n",
    "        valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        # 데이터 제너레이터 생성\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=self.img_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        valid_generator = valid_datagen.flow_from_directory(\n",
    "            val_dir,\n",
    "            target_size=self.img_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        test_generator = valid_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=self.img_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        return train_generator, valid_generator, test_generator\n",
    "    \n",
    "    def train(self, train_generator, valid_generator, epochs=20):\n",
    "        \"\"\"모델 훈련\"\"\"\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'best_model.keras',  # .h5 대신 .keras 사용\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=5,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,\n",
    "                patience=3\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        self.history = self.model.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=valid_generator,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        return self.history\n",
    "    \n",
    "    def evaluate(self, test_generator):\n",
    "        \"\"\"모델 평가 및 다양한 지표 계산\"\"\"\n",
    "        # 예측 수행\n",
    "        predictions = self.model.predict(test_generator)\n",
    "        y_pred = (predictions > 0.5).astype(int)\n",
    "        y_true = test_generator.labels\n",
    "        \n",
    "        # 분류 보고서 출력\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=['OK', 'NG']))\n",
    "        \n",
    "        # 혼동 행렬 시각화\n",
    "        self.plot_confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # ROC 커브 시각화\n",
    "        self.plot_roc_curve(y_true, predictions)\n",
    "        \n",
    "        # 학습 곡선 시각화\n",
    "        self.plot_learning_curves()\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_true, y_pred):\n",
    "        \"\"\"혼동 행렬 시각화\"\"\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=['OK', 'NG'],\n",
    "                   yticklabels=['OK', 'NG'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_roc_curve(self, y_true, y_pred_proba):\n",
    "        \"\"\"ROC 커브 시각화\"\"\"\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "                label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_learning_curves(self):\n",
    "        \"\"\"학습 곡선 시각화\"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # 손실 그래프\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history.history['loss'], label='Training Loss')\n",
    "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # 정확도 그래프\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    # 설정\n",
    "    DATA_DIR = 'preprocessed_high-pass/kernel_size_1'  # 데이터 디렉토리 경로\n",
    "    IMG_SIZE = (480, 480)\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 20\n",
    "    \n",
    "    # 분류기 초기화 및 모델 생성\n",
    "    classifier = DefectClassifier(img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "    model = classifier.create_model()\n",
    "    \n",
    "    # 데이터 준비\n",
    "    train_generator, valid_generator, test_generator = classifier.prepare_data(DATA_DIR)\n",
    "    \n",
    "    # 모델 훈련\n",
    "    history = classifier.train(train_generator, valid_generator, epochs=EPOCHS)\n",
    "    \n",
    "    # 모델 평가\n",
    "    classifier.evaluate(test_generator)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c69de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
